{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ec11c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe64b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "   def __init__(self, latent_dim=20):\n",
    "       super(VAE, self).__init__()\n",
    "       self.encoder = Encoder(latent_dim)\n",
    "       self.decoder = Decoder(latent_dim)\n",
    "\n",
    "   def forward(self,inputs):\n",
    "     z_mean, z_log_var = self.encoder(inputs)\n",
    "     z = self.reparameterize(z_mean, z_log_var)\n",
    "     reconstructed = self.decoder(z)\n",
    "     return reconstructed, z_mean, z_log_var\n",
    "\n",
    "   def reparameterize(self, mu, log_var):\n",
    "     std = torch.exp(0.5 * log_var)\n",
    "     eps = torch.randn_like(std)\n",
    "     return mu + (eps * std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca05f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bbbe12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#MLP block\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_dim,\n",
    "                 block_sizes,\n",
    "                 last_linear=True,\n",
    "                 **kwargs) -> None:\n",
    "\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.last_linear = last_linear\n",
    "\n",
    "        current_dim = in_dim\n",
    "\n",
    "        blocks = []\n",
    "        for i in range(len(block_sizes)):\n",
    "            linear = nn.Linear(current_dim, block_sizes[i])\n",
    "            blocks.append(linear)\n",
    "            if i < len(block_sizes)-1 or not last_linear:\n",
    "                act = nn.ReLU()\n",
    "                blocks.append(act)\n",
    "            current_dim = block_sizes[i]\n",
    "        self.mlp = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, input, transpose=False):\n",
    "        if transpose:\n",
    "            return self._transpose_call(input)\n",
    "        else:\n",
    "            return self.mlp(input)\n",
    "    \n",
    "    def _transpose_call(self, input):\n",
    "        out = input\n",
    "        for layer in reversed(self.mlp):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                out = torch.matmul(out, layer.weight)\n",
    "            else:\n",
    "                out = layer(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "#Residual attention block \n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim=128,\n",
    "        num_heads=8,\n",
    "        **kwargs\n",
    "        ):\n",
    "        super(TransformerLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        #Dropout\n",
    "        self.do = nn.Dropout(p=0.2)\n",
    "\n",
    "        #Multi-head attention\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.mha = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim, \n",
    "            num_heads=num_heads\n",
    "            )\n",
    "        \n",
    "        #MLP\n",
    "        self.mlp = MLP(embed_dim, [4*embed_dim, embed_dim])\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None, attn_mask=None):\n",
    "        mha,_ = self.mha(x, x, x, mask, attn_mask=attn_mask, need_weights=False)\n",
    "        mha = self.do(mha)\n",
    "        x = self.norm1(x + mha)\n",
    "        x = self.norm2(x + self.do(self.mlp(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a68b5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = TransformerLayer(embed_dim=512)\n",
    "src = torch.rand((10, 512))\n",
    "out = transformer_model(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d1e87d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0e22db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransMLPBlock(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_dim, hidden_dim, num_heads, **kwargs):\n",
    "#         super(TransMLPBlock, self).__init__(**kwargs)\n",
    "        \n",
    "#         self.trans_layer = TransformerLayer(embed_dim=input_dim,\n",
    "#                                             num_heads=num_heads)\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "#         self.mlp = MLP(input_dim, [input_dim//2, hidden_dim])\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.trans_layer(x)\n",
    "#         out = self.dropout(out)\n",
    "#         out = self.mlp(out)\n",
    "#         return out\n",
    "    \n",
    "\n",
    "class TransMLPBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, mlp, input_dim, num_heads, transpose_mlp=False, **kwargs):\n",
    "        super(TransMLPBlock, self).__init__(**kwargs)\n",
    "        \n",
    "        self.trans_layer = TransformerLayer(embed_dim=input_dim,\n",
    "                                            num_heads=num_heads)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.mlp = mlp\n",
    "        self.transpose_mlp = transpose_mlp\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.trans_layer(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.mlp(out, transpose=self.transpose_mlp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "66197a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = TransMLPBlock(512, 14)\n",
    "out = block(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "17da3b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 14])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc06034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, K, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        \n",
    "        blocks = [TransMLPBlock(input_dim, 64, num_heads=5),\n",
    "                   TransMLPBlock(64, 32, num_heads=4),\n",
    "                   TransMLPBlock(32, K, num_heads=4)]\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f0304da",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(100, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2d39c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.rand((10, 100))\n",
    "out = encoder(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6cd1e444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "afd14ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, K, **kwargs):\n",
    "        super(TransAE, self).__init__(**kwargs)\n",
    "        \n",
    "        mlps = [MLP(input_dim, [64, 64]),\n",
    "                MLP(64, [32, 32]),\n",
    "                MLP(32, [16, K])]\n",
    "        \n",
    "        blocks = [TransMLPBlock(mlps[0], input_dim, num_heads=5),\n",
    "                  TransMLPBlock(mlps[1], 64, num_heads=4),\n",
    "                  TransMLPBlock(mlps[2], 32, num_heads=4)]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*blocks)\n",
    "        \n",
    "        blocks = [TransMLPBlock(mlps[2], K, num_heads=3, transpose_mlp=True),\n",
    "                  TransMLPBlock(mlps[1], 32, num_heads=4, transpose_mlp=True),\n",
    "                  TransMLPBlock(mlps[0], 64, num_heads=4, transpose_mlp=True)]\n",
    "        \n",
    "        self.decoder = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        code = self.encoder(inputs)\n",
    "        out = self.decoder(code)\n",
    "        return out\n",
    "    \n",
    "#     def forward(self, inputs):\n",
    "#         z_mean, z_log_var = self.encoder(inputs)\n",
    "#         z = self.reparameterize(z_mean, z_log_var)\n",
    "#         reconstructed = self.decoder(z)\n",
    "#         return reconstructed, z_mean, z_log_var\n",
    "\n",
    "#     def reparameterize(self, mu, log_var):\n",
    "#         std = torch.exp(0.5 * log_var)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return mu + (eps * std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "af023d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = TransAE(100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8d2f7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(200, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1f5bd462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 3])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = ae.encoder(x)\n",
    "code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b44a0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ae.decoder(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f253420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1c317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b7d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10be280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a3d9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(10, [8, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66047f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(20, 10)\n",
    "out = mlp(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0950b3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ada38836",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = mlp(out, transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd1dfe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c89f6350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1223, 2.1223, 2.1223, 2.1223, 2.1223, 2.1223, 2.1223, 2.1223, 2.1223,\n",
       "         2.1223],\n",
       "        [0.2600, 0.2600, 0.2600, 0.2600, 0.2600, 0.2600, 0.2600, 0.2600, 0.2600,\n",
       "         0.2600],\n",
       "        [1.1222, 1.1222, 1.1222, 1.1222, 1.1222, 1.1222, 1.1222, 1.1222, 1.1222,\n",
       "         1.1222],\n",
       "        [0.1715, 0.1715, 0.1715, 0.1715, 0.1715, 0.1715, 0.1715, 0.1715, 0.1715,\n",
       "         0.1715],\n",
       "        [3.5680, 3.5680, 3.5680, 3.5680, 3.5680, 3.5680, 3.5680, 3.5680, 3.5680,\n",
       "         3.5680],\n",
       "        [0.4781, 0.4781, 0.4781, 0.4781, 0.4781, 0.4781, 0.4781, 0.4781, 0.4781,\n",
       "         0.4781],\n",
       "        [0.1711, 0.1711, 0.1711, 0.1711, 0.1711, 0.1711, 0.1711, 0.1711, 0.1711,\n",
       "         0.1711],\n",
       "        [1.3130, 1.3130, 1.3130, 1.3130, 1.3130, 1.3130, 1.3130, 1.3130, 1.3130,\n",
       "         1.3130]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.mlp[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ba34b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10, 4)\n",
    "rec = mlp(x, transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3b5a7d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6551b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c160daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
